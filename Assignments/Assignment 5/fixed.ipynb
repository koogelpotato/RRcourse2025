{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set up working directory\n",
    "BASE_PATH = \"Z:/File folders/Teaching/Reproducible Research/2023/Repository/RRcourse2023/6. Coding and documentation\"\n",
    "os.chdir(BASE_PATH)\n",
    "\n",
    "# Load O*NET task data\n",
    "task_data = pd.read_csv(\"Data/onet_tasks.csv\")\n",
    "\n",
    "# Load Eurostat employment data sheets\n",
    "def load_eurostat_data():\n",
    "    \"\"\"Load Eurostat employment data from Excel sheets\"\"\"\n",
    "    sheets = [\"ISCO1\", \"ISCO2\", \"ISCO3\", \"ISCO4\", \n",
    "             \"ISCO5\", \"ISCO6\", \"ISCO7\", \"ISCO8\", \"ISCO9\"]\n",
    "    \n",
    "    # Dictionary to store loaded DataFrames\n",
    "    employment_data = {}\n",
    "    for sheet_name in sheets:\n",
    "        df = pd.read_excel(\n",
    "            \"Data/Eurostat_employment_isco.xlsx\",\n",
    "            sheet_name=sheet_name\n",
    "        )\n",
    "        employment_data[sheet_name] = df\n",
    "        \n",
    "    return employment_data\n",
    "\n",
    "# Load all sheets into memory\n",
    "employment_data = load_eurostat_data()\n",
    "\n",
    "def calculate_country_totals(country_name):\n",
    "    \"\"\"Calculate total workers for a country across all ISCO levels\"\"\"\n",
    "    total_workers = sum(df[country_name] \n",
    "                       for df in employment_data.values() \n",
    "                       if country_name in df.columns)\n",
    "    return total_workers\n",
    "\n",
    "# Calculate totals for selected countries\n",
    "countries_of_interest = [\"Belgium\", \"Spain\", \"Poland\"]\n",
    "country_totals = {\n",
    "    country: calculate_country_totals(country)\n",
    "    for country in countries_of_interest\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def assign_isco_categories(dataframes):\n",
    "    \"\"\"\n",
    "    Assign ISCO category numbers to each dataframe.\n",
    "    \n",
    "    Args:\n",
    "        dataframes (list): List of pandas DataFrames containing employment data\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary mapping ISCO levels to their corresponding DataFrames\n",
    "    \"\"\"\n",
    "    return {f\"isco{i}\": df.assign(ISCO=i) \n",
    "            for i, df in enumerate(dataframes, 1)}\n",
    "\n",
    "def merge_datasets(dataframes_dict):\n",
    "    \"\"\"\n",
    "    Merge all datasets vertically into a single DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        dataframes_dict (dict): Dictionary of DataFrames with ISCO assignments\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Concatenated dataset with ISCO category information\n",
    "    \"\"\"\n",
    "    return pd.concat(dataframes_dict.values(), ignore_index=True)\n",
    "\n",
    "def replicate_totals(all_data, totals_dict):\n",
    "    \"\"\"\n",
    "    Replicate country totals across ISCO categories.\n",
    "    \n",
    "    Args:\n",
    "        all_data (DataFrame): Concatenated dataset\n",
    "        totals_dict (dict): Dictionary of country totals\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Dataset with replicated totals\n",
    "    \"\"\"\n",
    "    for country in totals_dict.keys():\n",
    "        all_data[f\"total_{country}\"] = pd.concat([totals_dict[country]] * 9, \n",
    "                                               ignore_index=True)\n",
    "    return all_data\n",
    "\n",
    "def calculate_shares(dataset):\n",
    "    \"\"\"\n",
    "    Calculate occupation shares for each country.\n",
    "    \n",
    "    Args:\n",
    "        dataset (DataFrame): Dataset with employment and total data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Dataset with share calculations added\n",
    "    \"\"\"\n",
    "    countries = ['Belgium', 'Spain', 'Poland']\n",
    "    for country in countries:\n",
    "        dataset[f'share_{country.lower()}'] = (\n",
    "            dataset[country] / dataset[f'total_{country}']\n",
    "        )\n",
    "    return dataset\n",
    "\n",
    "# Process the datasets\n",
    "isco_dataframes = [isco1, isco2, isco3, isco4, isco5, isco6, isco7, isco8, isco9]\n",
    "\n",
    "# Step 1: Assign ISCO categories\n",
    "isco_with_categories = assign_isco_categories(isco_dataframes)\n",
    "\n",
    "# Step 2: Merge all datasets\n",
    "merged_data = merge_datasets(isco_with_categories)\n",
    "\n",
    "# Step 3: Add country totals\n",
    "merged_data = replicate_totals(merged_data, {\n",
    "    'Belgium': total_Belgium,\n",
    "    'Spain': total_Spain,\n",
    "    'Poland': total_Poland\n",
    "})\n",
    "\n",
    "# Step 4: Calculate shares\n",
    "final_data = calculate_shares(merged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's look at the task data. We want the first digit of the ISCO variable only\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "task_data[\"isco08_1dig\"] = task_data[\"isco08\"].astype(str).str[:1].astype(int)\n",
    "\n",
    "# And we'll calculate the mean task values at a 1-digit level \n",
    "# (more on what these tasks are below)\n",
    "aggdata = task_data.groupby([\"isco08_1dig\"]).mean()\n",
    "aggdata = aggdata.drop(columns=[\"isco08\"])\n",
    "\n",
    "# We'll be interested in tracking the intensity of Non-routine cognitive analytical tasks\n",
    "# Using a framework reminiscent of the work by David Autor.\n",
    "\n",
    "#These are the ones we're interested in:\n",
    "# Non-routine cognitive analytical\n",
    "# 4.A.2.a.4 Analyzing Data or Information\n",
    "# 4.A.2.b.2 Thinking Creatively\n",
    "# 4.A.4.a.1 Interpreting the Meaning of Information for Others\n",
    "\n",
    "#Let's combine the data.\n",
    "combined = pd.merge(all_data, aggdata, left_on='ISCO', right_on='isco08_1dig', how='left')\n",
    "# Traditionally, the first step is to standardise the task values using weights \n",
    "# defined by share of occupations in the labour force. This should be done separately\n",
    "# for each country. Standardisation -> getting the mean to 0 and std. dev. to 1.\n",
    "# Let's do this for each of the variables that interests us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import gmean\n",
    "import numpy as np\n",
    "\n",
    "def calculate_standardized_values(data, column, weight_column):\n",
    "    \"\"\"\n",
    "    Calculate standardized values for a given column using weighted statistics.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Input dataset\n",
    "        column (str): Column containing values to standardize\n",
    "        weight_column (str): Column containing weights\n",
    "        \n",
    "    Returns:\n",
    "        Series: Standardized values\n",
    "    \"\"\"\n",
    "    mean = np.average(data[column], weights=data[weight_column])\n",
    "    std_dev = np.sqrt(np.average((data[column] - mean)**2, \n",
    "                                weights=data[weight_column]))\n",
    "    return (data[column] - mean) / std_dev\n",
    "\n",
    "def process_task_items(data):\n",
    "    \"\"\"\n",
    "    Process standardized calculations for all task items and countries.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Input dataset containing task items and weights\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Dataset with standardized columns added\n",
    "    \"\"\"\n",
    "    # Define task items and countries\n",
    "    task_items = [\"t_4A2a4\", \"t_4A2b2\", \"t_4A4a1\"]\n",
    "    countries = [\"Belgium\", \"Poland\", \"Spain\"]\n",
    "    \n",
    "    # Process each task item\n",
    "    for task_item in task_items:\n",
    "        # Process each country\n",
    "        for country in countries:\n",
    "            weight_column = f\"share_{country}\"\n",
    "            result_column = f\"std_{country}_t_{task_item}\"\n",
    "            \n",
    "            # Calculate standardized values\n",
    "            data[result_column] = calculate_standardized_values(\n",
    "                data, task_item, weight_column\n",
    "            )\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Process all task items\n",
    "combined = process_task_items(combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_nrca_scores(data, country):\n",
    "    \"\"\"\n",
    "    Calculate Non-Routine Cognitive Analytical (NRCA) task scores for a country.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Input dataset\n",
    "        country (str): Country name (e.g., \"Belgium\", \"Poland\", \"Spain\")\n",
    "        \n",
    "    Returns:\n",
    "        Series: Combined NRCA scores\n",
    "    \"\"\"\n",
    "    task_columns = [\n",
    "        f\"std_{country}_t_4A2a4\",\n",
    "        f\"std_{country}_t_4A2b2\",\n",
    "        f\"std_{country}_t_4A4a1\"\n",
    "    ]\n",
    "    return data[task_columns].sum(axis=1)\n",
    "\n",
    "def standardize_values(data, column, weight_column):\n",
    "    \"\"\"\n",
    "    Standardize values using weighted statistics.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Input dataset\n",
    "        column (str): Column to standardize\n",
    "        weight_column (str): Column containing weights\n",
    "        \n",
    "    Returns:\n",
    "        Series: Standardized values\n",
    "    \"\"\"\n",
    "    mean = np.average(data[column], weights=data[weight_column])\n",
    "    std_dev = np.sqrt(np.average((data[column] - mean)**2, \n",
    "                                weights=data[weight_column]))\n",
    "    return (data[column] - mean) / std_dev\n",
    "\n",
    "def calculate_country_aggregates(data, country):\n",
    "    \"\"\"\n",
    "    Calculate time-series aggregates for a country's NRCA scores.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Input dataset\n",
    "        country (str): Country name\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame: Aggregated time-series data\n",
    "    \"\"\"\n",
    "    # Calculate NRCA scores\n",
    "    data[f\"{country}_NRCA\"] = calculate_nrca_scores(data, country)\n",
    "    \n",
    "    # Standardize scores\n",
    "    data[f\"std_{country}_NRCA\"] = standardize_values(\n",
    "        data, f\"{country}_NRCA\", f\"share_{country}\"\n",
    "    )\n",
    "    \n",
    "    # Calculate weighted aggregates\n",
    "    data[f\"multip_{country}_NRCA\"] = (\n",
    "        data[f\"std_{country}_NRCA\"] * data[f\"share_{country}\"]\n",
    "    )\n",
    "    \n",
    "    # Aggregate by time\n",
    "    return data.groupby(\"TIME\")[f\"multip_{country}_NRCA\"].sum().reset_index()\n",
    "\n",
    "def plot_nrca_trends(data, country):\n",
    "    \"\"\"\n",
    "    Plot NRCA trends over time for a country.\n",
    "    \n",
    "    Args:\n",
    "        data (DataFrame): Aggregated time-series data\n",
    "        country (str): Country name\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(data[\"TIME\"], data[f\"multip_{country}_NRCA\"])\n",
    "    plt.xticks(range(0, len(data), 3), data[\"TIME\"][::3])\n",
    "    plt.title(f\"NRCA Trends for {country}\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Weighted NRCA Score\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Process data for each country\n",
    "countries = [\"Belgium\", \"Poland\", \"Spain\"]\n",
    "for country in countries:\n",
    "    aggregates = calculate_country_aggregates(combined, country)\n",
    "    plot_nrca_trends(aggregates, country)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
